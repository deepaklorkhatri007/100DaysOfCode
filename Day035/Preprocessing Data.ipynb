{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "x = np.array([[ 33., 4., 5.],\n",
    "             [ 23., 65., 9.],\n",
    "             [ 2., 23., 56.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05791041, -1.04631049, -0.79171529],\n",
       "       [ 0.28382962,  1.34712476, -0.61897741],\n",
       "       [-1.34174003, -0.30081427,  1.41069269]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardinzing the data\n",
    "# data should have mean = 0 anf standard deviation = 1\n",
    "x_scale = preprocessing.scale(x)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.40148683e-17, -1.29526020e-16,  7.40148683e-17])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean should be close to 0 after scaling\n",
    "x_scale.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard deviation should be 1 after scaling\n",
    "x_scale.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78571429, 0.0952381 , 0.11904762],\n",
       "       [0.2371134 , 0.67010309, 0.09278351],\n",
       "       [0.02469136, 0.28395062, 0.69135802]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the data\n",
    "# l1 norm -> manhattan distance\n",
    "x_norm_l1 = preprocessing.normalize(x, norm = 'l1')\n",
    "x_norm_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98169079, 0.11899282, 0.14874103],\n",
       "       [0.33077265, 0.93479228, 0.12943278],\n",
       "       [0.03301841, 0.3797117 , 0.92451545]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 norm -> euclideandistance\n",
    "x_norm_l2 = preprocessing.normalize(x, norm = 'l2')\n",
    "x_norm_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.67741935, 1.        , 0.07843137],\n",
       "       [0.        , 0.31147541, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the feature to a range\n",
    "# scaling the data within 0-1\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_min_mac = min_max_scaler.fit_transform(x)\n",
    "x_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [0.67741935, 1.        , 0.07843137],\n",
       "       [0.        , 0.31147541, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the data within data range of -10-10\n",
    "min_max_scaler_wfr = preprocessing.MinMaxScaler(feature_range = (-10, 10))\n",
    "x_min_max_wfr = min_max_scaler_wfr.fit_transform(x)\n",
    "x_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [0., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binaring features -> preasent(1) or absent(0) based on a threshold\n",
    "binarizer = preprocessing.Binarizer(threshold = (10))\n",
    "x_binarized = binarizer.transform(x)\n",
    "x_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing data\n",
    "from numpy import nan\n",
    "x2 = np.array([[2., 4., 8., nan],\n",
    "               [3., nan, 5., 1],\n",
    "               [9., 3., 11., nan],\n",
    "               [14., nan, 7., 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. ,  4. ,  8. ,  3.5],\n",
       "       [ 3. ,  3.5,  5. ,  1. ],\n",
       "       [ 9. ,  3. , 11. ,  3.5],\n",
       "       [14. ,  3.5,  7. ,  6. ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# median stategy of imputing the data\n",
    "# replace every nan with the mean of the row (default axis:0)\n",
    "imp_mean = preprocessing.Imputer(strategy = \"mean\")\n",
    "x2_imputed_mean = imp_mean.fit_transform(x2)\n",
    "x2_imputed_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. ,  4. ,  8. ,  3.5],\n",
       "       [ 3. ,  3.5,  5. ,  1. ],\n",
       "       [ 9. ,  3. , 11. ,  3.5],\n",
       "       [14. ,  3.5,  7. ,  6. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median strategy\n",
    "imp_median = preprocessing.Imputer(strategy = \"median\")\n",
    "x2_imputed_median = imp_median.fit_transform(x2)\n",
    "x2_imputed_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  8.,  1.],\n",
       "       [ 3.,  3.,  5.,  1.],\n",
       "       [ 9.,  3., 11.,  1.],\n",
       "       [14.,  3.,  7.,  6.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent stategy\n",
    "imp_mf = preprocessing.Imputer(strategy = \"most_frequent\")\n",
    "x2_imputed_mf = imp_mf.fit_transform(x2)\n",
    "x2_imputed_mf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
